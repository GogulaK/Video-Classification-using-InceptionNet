{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of test1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nex6T7Glozr7",
        "colab_type": "code",
        "outputId": "1313b85f-eb63-4405-c4c6-e69a0fcdf897",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvaMhVIqo2Qc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "import os\n",
        "import cv2\n",
        "import math\n",
        "\n",
        "\n",
        "def load_graph(model_file):\n",
        "  graph = tf.Graph()\n",
        "  graph_def = tf.GraphDef()\n",
        "\n",
        "  with open(model_file, \"rb\") as f:\n",
        "    graph_def.ParseFromString(f.read())\n",
        "  with graph.as_default():\n",
        "    tf.import_graph_def(graph_def)\n",
        "\n",
        "  return graph\n",
        "\n",
        "\n",
        "def read_tensor_from_image_file(file_name,\n",
        "                                input_height=299,\n",
        "                                input_width=299,\n",
        "                                input_mean=0,\n",
        "                                input_std=255):\n",
        "  input_name = \"file_reader\"\n",
        "  output_name = \"normalized\"\n",
        "  file_reader = tf.read_file(file_name, input_name)\n",
        "  if file_name.endswith(\".png\"):\n",
        "    image_reader = tf.image.decode_png(\n",
        "        file_reader, channels=3, name=\"png_reader\")\n",
        "  elif file_name.endswith(\".gif\"):\n",
        "    image_reader = tf.squeeze(\n",
        "        tf.image.decode_gif(file_reader, name=\"gif_reader\"))\n",
        "  elif file_name.endswith(\".bmp\"):\n",
        "    image_reader = tf.image.decode_bmp(file_reader, name=\"bmp_reader\")\n",
        "  else:\n",
        "    image_reader = tf.image.decode_jpeg(\n",
        "        file_reader, channels=3, name=\"jpeg_reader\")\n",
        "  float_caster = tf.cast(image_reader, tf.float32)\n",
        "  dims_expander = tf.expand_dims(float_caster, 0)\n",
        "  resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width])\n",
        "  normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std])\n",
        "  sess = tf.compat.v1.Session()\n",
        "  result = sess.run(normalized)\n",
        "\n",
        "  return result\n",
        "\n",
        "\n",
        "def load_labels(label_file):\n",
        "  label = []\n",
        "  proto_as_ascii_lines = tf.gfile.GFile(label_file).readlines()\n",
        "  for l in proto_as_ascii_lines:\n",
        "    label.append(l.rstrip())\n",
        "  return label\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  #file_name = \"/content/drive/My Drive/grace_hopper.jpg\"\n",
        "  model_file = \\\n",
        "    \"/content/drive/My Drive/inception_v3_2016_08_28_frozen.pb\"\n",
        "  label_file = \"/content/drive/My Drive/imagenet_slim_labels.txt\"\n",
        "  input_height = 299\n",
        "  input_width = 299\n",
        "  input_mean = 0\n",
        "  input_std = 255\n",
        "  input_layer = \"input\"\n",
        "  output_layer = \"InceptionV3/Predictions/Reshape_1\"\n",
        "\n",
        "  graph = load_graph(model_file)\n",
        "  \n",
        "  input_name = \"import/\" + input_layer\n",
        "  output_name = \"import/\" + output_layer\n",
        "  input_operation = graph.get_operation_by_name(input_name)\n",
        "  output_operation = graph.get_operation_by_name(output_name)\n",
        "  \n",
        "  writer = None\n",
        "  \n",
        "  video_path = \"/content/drive/My Drive/football.mp4\" ## path_to_video\n",
        "  \n",
        "  with tf.compat.v1.Session(graph=graph) as sess:\n",
        "    \n",
        "    ## start video capture.... read video file\n",
        "    video_capture = cv2.VideoCapture(video_path)\n",
        "    i = 0\n",
        "    while True: \n",
        "        frame = video_capture.read()[1] ## get current frame\n",
        "        frameId = video_capture.get(1) ## current frame number\n",
        "        i = i + 1\n",
        "        cv2.imwrite(filename=\"/content/drive/My Drive/screens/\"+str(i)+\"alpha.png\", img=frame); ## write frame image to file\n",
        "        \n",
        "        file_name = \"/content/drive/My Drive/screens/\"+str(i)+\"alpha.png\" \n",
        "        \n",
        "        ## convert frame to tensor\n",
        "        t = read_tensor_from_image_file(\n",
        "        file_name,\n",
        "        input_height=input_height,\n",
        "        input_width=input_width,\n",
        "        input_mean=input_mean,\n",
        "        input_std=input_std)\n",
        "\n",
        "        predictions = sess.run(output_operation.outputs[0], {\n",
        "        input_operation.outputs[0]: t })\n",
        "        predictions = np.squeeze(predictions) ## predictions\n",
        "        \n",
        "        top_k = predictions.argsort()[-1:][::-1] ## top_k predictions.. set to top1 prediction for every frame\n",
        "        labels = load_labels(label_file)\n",
        "        pos = 1\n",
        "        for i in top_k:\n",
        "            human_string = labels[i]\n",
        "            score = predictions[i]\n",
        "            cv2.putText(frame, '%s (score = %.5f)' % (human_string, score), (40, 40 * pos), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255, 255, 255))\n",
        "            print('%s (score = %.5f)' % (human_string, score))\n",
        "            pos = pos + 1\n",
        "        print (\"\\n\\n\")\n",
        "        if writer is None:\n",
        "            ## initialize video writer\n",
        "            fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
        "            writer = cv2.VideoWriter(\"recognized.avi\", fourcc, 10,\n",
        "                (frame.shape[1], frame.shape[0]), True)\n",
        "  \n",
        "        ## write the output frame to video\n",
        "        writer.write(frame)\n",
        "        cv2.waitKey(1)\n",
        "    writer.release()\n",
        "    video_capture.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}